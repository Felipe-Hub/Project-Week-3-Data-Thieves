{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "glassdoor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRFR1_thnEW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from lxml import etree\n",
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpDC-HSXnEXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting all the pages with listings\n",
        "pages_url = list(map(lambda pag: 'https://www.glassdoor.com/Job/portugal-data-jobs-SRCH_IL.0,8_IN195_KE9,13_IP' + pag + '.htm?radius=25', [str(pages) for pages in list(range(1,31))]))\n",
        "\n",
        "#getting all the jobs links from all the pages\n",
        "def grab_links(pages_url):\n",
        "  job_links = []\n",
        "  for url in pages_url:\n",
        "    response_url = requests.get(url, headers={'user-agent': 'Mozilla/5.0'})\n",
        "    soup_url = BeautifulSoup(response_url.content, 'lxml')\n",
        "    links_all = [element.get('href') for element in soup_url.find_all('a')]\n",
        "    links = set(list(filter(lambda x: x.startswith('/partner') if x else False, links_all)))\n",
        "    job_links += links\n",
        "  return job_links\n",
        "\n",
        "description_url = grab_links(pages_url)\n",
        "\n",
        "#joining the link to whole url\n",
        "\n",
        "description_links = set(list(map(lambda x: 'https://www.glassdoor.com' + x, description_url)))\n",
        "\n",
        "number_of_links = len(description_links) # 2017"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzafd4L4nEXS",
        "colab_type": "code",
        "outputId": "9361d6d9-dd3c-4de4-ee13-2edb471cff07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# access each job description url to get list of soups\n",
        "def get_info(links):\n",
        "    positions = []\n",
        "    companies = []\n",
        "    cities = []\n",
        "    skills = []\n",
        "    count = 0   \n",
        "    for link in links:\n",
        "        response_link = requests.get(link, headers={'user-agent': 'Mozilla/5.0'})\n",
        "        soup_link = BeautifulSoup(response_link.content, 'lxml')\n",
        "        position = [element.text.strip() for element in soup_link.find_all('h2', attrs = {'class':'noMargTop margBotXs strong'})]\n",
        "        company = [element.text.strip() for element in soup_link.find_all('span', attrs = {'class':'strong ib'})]\n",
        "        city = [element.text.replace('\\xa0', '').replace('â€“', '').strip() for element in soup_link.find_all('span', attrs = {'class':'subtle ib'})]\n",
        "        skill = [element.text for element in soup_link.find_all('li')][29:-28]\n",
        "        positions += position\n",
        "        companies += company\n",
        "        cities += city\n",
        "        skills += skill\n",
        "        count += 1\n",
        "        print('Processing... {} of 2023'.format(count) )\n",
        "    return [positions, companies, cities, skills]\n",
        "\n",
        "#descriptions_response = list(map(lambda x: requests.get(x, headers={'user-agent': 'Mozilla/5.0'}), description_links)\n",
        "info_list = get_info(description_links)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing... 1 of 2023\n",
            "Processing... 2 of 2023\n",
            "Processing... 3 of 2023\n",
            "Processing... 4 of 2023\n",
            "Processing... 5 of 2023\n",
            "Processing... 6 of 2023\n",
            "Processing... 7 of 2023\n",
            "Processing... 8 of 2023\n",
            "Processing... 9 of 2023\n",
            "Processing... 10 of 2023\n",
            "Processing... 11 of 2023\n",
            "Processing... 12 of 2023\n",
            "Processing... 13 of 2023\n",
            "Processing... 14 of 2023\n",
            "Processing... 15 of 2023\n",
            "Processing... 16 of 2023\n",
            "Processing... 17 of 2023\n",
            "Processing... 18 of 2023\n",
            "Processing... 19 of 2023\n",
            "Processing... 20 of 2023\n",
            "Processing... 21 of 2023\n",
            "Processing... 22 of 2023\n",
            "Processing... 23 of 2023\n",
            "Processing... 24 of 2023\n",
            "Processing... 25 of 2023\n",
            "Processing... 26 of 2023\n",
            "Processing... 27 of 2023\n",
            "Processing... 28 of 2023\n",
            "Processing... 29 of 2023\n",
            "Processing... 30 of 2023\n",
            "Processing... 31 of 2023\n",
            "Processing... 32 of 2023\n",
            "Processing... 33 of 2023\n",
            "Processing... 34 of 2023\n",
            "Processing... 35 of 2023\n",
            "Processing... 36 of 2023\n",
            "Processing... 37 of 2023\n",
            "Processing... 38 of 2023\n",
            "Processing... 39 of 2023\n",
            "Processing... 40 of 2023\n",
            "Processing... 41 of 2023\n",
            "Processing... 42 of 2023\n",
            "Processing... 43 of 2023\n",
            "Processing... 44 of 2023\n",
            "Processing... 45 of 2023\n",
            "Processing... 46 of 2023\n",
            "Processing... 47 of 2023\n",
            "Processing... 48 of 2023\n",
            "Processing... 49 of 2023\n",
            "Processing... 50 of 2023\n",
            "Processing... 51 of 2023\n",
            "Processing... 52 of 2023\n",
            "Processing... 53 of 2023\n",
            "Processing... 54 of 2023\n",
            "Processing... 55 of 2023\n",
            "Processing... 56 of 2023\n",
            "Processing... 57 of 2023\n",
            "Processing... 58 of 2023\n",
            "Processing... 59 of 2023\n",
            "Processing... 60 of 2023\n",
            "Processing... 61 of 2023\n",
            "Processing... 62 of 2023\n",
            "Processing... 63 of 2023\n",
            "Processing... 64 of 2023\n",
            "Processing... 65 of 2023\n",
            "Processing... 66 of 2023\n",
            "Processing... 67 of 2023\n",
            "Processing... 68 of 2023\n",
            "Processing... 69 of 2023\n",
            "Processing... 70 of 2023\n",
            "Processing... 71 of 2023\n",
            "Processing... 72 of 2023\n",
            "Processing... 73 of 2023\n",
            "Processing... 74 of 2023\n",
            "Processing... 75 of 2023\n",
            "Processing... 76 of 2023\n",
            "Processing... 77 of 2023\n",
            "Processing... 78 of 2023\n",
            "Processing... 79 of 2023\n",
            "Processing... 80 of 2023\n",
            "Processing... 81 of 2023\n",
            "Processing... 82 of 2023\n",
            "Processing... 83 of 2023\n",
            "Processing... 84 of 2023\n",
            "Processing... 85 of 2023\n",
            "Processing... 86 of 2023\n",
            "Processing... 87 of 2023\n",
            "Processing... 88 of 2023\n",
            "Processing... 89 of 2023\n",
            "Processing... 90 of 2023\n",
            "Processing... 91 of 2023\n",
            "Processing... 92 of 2023\n",
            "Processing... 93 of 2023\n",
            "Processing... 94 of 2023\n",
            "Processing... 95 of 2023\n",
            "Processing... 96 of 2023\n",
            "Processing... 97 of 2023\n",
            "Processing... 98 of 2023\n",
            "Processing... 99 of 2023\n",
            "Processing... 100 of 2023\n",
            "Processing... 101 of 2023\n",
            "Processing... 102 of 2023\n",
            "Processing... 103 of 2023\n",
            "Processing... 104 of 2023\n",
            "Processing... 105 of 2023\n",
            "Processing... 106 of 2023\n",
            "Processing... 107 of 2023\n",
            "Processing... 108 of 2023\n",
            "Processing... 109 of 2023\n",
            "Processing... 110 of 2023\n",
            "Processing... 111 of 2023\n",
            "Processing... 112 of 2023\n",
            "Processing... 113 of 2023\n",
            "Processing... 114 of 2023\n",
            "Processing... 115 of 2023\n",
            "Processing... 116 of 2023\n",
            "Processing... 117 of 2023\n",
            "Processing... 118 of 2023\n",
            "Processing... 119 of 2023\n",
            "Processing... 120 of 2023\n",
            "Processing... 121 of 2023\n",
            "Processing... 122 of 2023\n",
            "Processing... 123 of 2023\n",
            "Processing... 124 of 2023\n",
            "Processing... 125 of 2023\n",
            "Processing... 126 of 2023\n",
            "Processing... 127 of 2023\n",
            "Processing... 128 of 2023\n",
            "Processing... 129 of 2023\n",
            "Processing... 130 of 2023\n",
            "Processing... 131 of 2023\n",
            "Processing... 132 of 2023\n",
            "Processing... 133 of 2023\n",
            "Processing... 134 of 2023\n",
            "Processing... 135 of 2023\n",
            "Processing... 136 of 2023\n",
            "Processing... 137 of 2023\n",
            "Processing... 138 of 2023\n",
            "Processing... 139 of 2023\n",
            "Processing... 140 of 2023\n",
            "Processing... 141 of 2023\n",
            "Processing... 142 of 2023\n",
            "Processing... 143 of 2023\n",
            "Processing... 144 of 2023\n",
            "Processing... 145 of 2023\n",
            "Processing... 146 of 2023\n",
            "Processing... 147 of 2023\n",
            "Processing... 148 of 2023\n",
            "Processing... 149 of 2023\n",
            "Processing... 150 of 2023\n",
            "Processing... 151 of 2023\n",
            "Processing... 152 of 2023\n",
            "Processing... 153 of 2023\n",
            "Processing... 154 of 2023\n",
            "Processing... 155 of 2023\n",
            "Processing... 156 of 2023\n",
            "Processing... 157 of 2023\n",
            "Processing... 158 of 2023\n",
            "Processing... 159 of 2023\n",
            "Processing... 160 of 2023\n",
            "Processing... 161 of 2023\n",
            "Processing... 162 of 2023\n",
            "Processing... 163 of 2023\n",
            "Processing... 164 of 2023\n",
            "Processing... 165 of 2023\n",
            "Processing... 166 of 2023\n",
            "Processing... 167 of 2023\n",
            "Processing... 168 of 2023\n",
            "Processing... 169 of 2023\n",
            "Processing... 170 of 2023\n",
            "Processing... 171 of 2023\n",
            "Processing... 172 of 2023\n",
            "Processing... 173 of 2023\n",
            "Processing... 174 of 2023\n",
            "Processing... 175 of 2023\n",
            "Processing... 176 of 2023\n",
            "Processing... 177 of 2023\n",
            "Processing... 178 of 2023\n",
            "Processing... 179 of 2023\n",
            "Processing... 180 of 2023\n",
            "Processing... 181 of 2023\n",
            "Processing... 182 of 2023\n",
            "Processing... 183 of 2023\n",
            "Processing... 184 of 2023\n",
            "Processing... 185 of 2023\n",
            "Processing... 186 of 2023\n",
            "Processing... 187 of 2023\n",
            "Processing... 188 of 2023\n",
            "Processing... 189 of 2023\n",
            "Processing... 190 of 2023\n",
            "Processing... 191 of 2023\n",
            "Processing... 192 of 2023\n",
            "Processing... 193 of 2023\n",
            "Processing... 194 of 2023\n",
            "Processing... 195 of 2023\n",
            "Processing... 196 of 2023\n",
            "Processing... 197 of 2023\n",
            "Processing... 198 of 2023\n",
            "Processing... 199 of 2023\n",
            "Processing... 200 of 2023\n",
            "Processing... 201 of 2023\n",
            "Processing... 202 of 2023\n",
            "Processing... 203 of 2023\n",
            "Processing... 204 of 2023\n",
            "Processing... 205 of 2023\n",
            "Processing... 206 of 2023\n",
            "Processing... 207 of 2023\n",
            "Processing... 208 of 2023\n",
            "Processing... 209 of 2023\n",
            "Processing... 210 of 2023\n",
            "Processing... 211 of 2023\n",
            "Processing... 212 of 2023\n",
            "Processing... 213 of 2023\n",
            "Processing... 214 of 2023\n",
            "Processing... 215 of 2023\n",
            "Processing... 216 of 2023\n",
            "Processing... 217 of 2023\n",
            "Processing... 218 of 2023\n",
            "Processing... 219 of 2023\n",
            "Processing... 220 of 2023\n",
            "Processing... 221 of 2023\n",
            "Processing... 222 of 2023\n",
            "Processing... 223 of 2023\n",
            "Processing... 224 of 2023\n",
            "Processing... 225 of 2023\n",
            "Processing... 226 of 2023\n",
            "Processing... 227 of 2023\n",
            "Processing... 228 of 2023\n",
            "Processing... 229 of 2023\n",
            "Processing... 230 of 2023\n",
            "Processing... 231 of 2023\n",
            "Processing... 232 of 2023\n",
            "Processing... 233 of 2023\n",
            "Processing... 234 of 2023\n",
            "Processing... 235 of 2023\n",
            "Processing... 236 of 2023\n",
            "Processing... 237 of 2023\n",
            "Processing... 238 of 2023\n",
            "Processing... 239 of 2023\n",
            "Processing... 240 of 2023\n",
            "Processing... 241 of 2023\n",
            "Processing... 242 of 2023\n",
            "Processing... 243 of 2023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCn6aHaSZNgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "info_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uJJM0IZZQg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "job = info_list[0]\n",
        "comp = set(info_list[1])\n",
        "city = info_list[2]\n",
        "skil = set(info_list[3])\n",
        "\n",
        "#cleaning skill text\n",
        "words_skill = ' '.join(skil).replace(',','').replace('.','').replace('(', '').replace(')', '').replace('/','').replace('/', '').replace('-', '').lower()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBjOeTwIp5CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# years of experience required\n",
        "\n",
        "experience_years = re.findall('\\d.y', words_skill)\n",
        "experience_plus = re.findall('\\d\\+', words_skill)\n",
        "exp_y_int = [int(n[0]) for n in experience_years]\n",
        "exp_p_int = [int(n[0]) for n in experience_plus]\n",
        "experience = exp_y_int + exp_p_int\n",
        "average = round(sum(experience)/len(experience), 2) # 3.46\n",
        "informed_exp = len(experience) # 208\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rtyqqd8qcoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bag of words\n",
        "\n",
        "stopwords =  ['a', 'as', 'about', 'after', 'all', 'also', 'always', 'am', 'an', 'and', 'any', 'are', 'at', 'be', 'been', 'being', 'but', 'by', 'came', 'can', 'cant', 'come', 'could', 'did', \"didn't\", 'do', 'does', \"doesn't\",'doing', \"don't\", 'else', 'for', 'from', 'get', 'give', 'goes', 'going', 'had', 'happen', 'has', 'have', 'having', 'how', 'i', 'if', 'ill', \"i'll\", \"i'm\",'in', 'into', 'is', \"isn't\", 'it', 'its', \"it's\", \"I've\", 'just', 'keep', 'let', 'like', 'made', 'make', 'many', 'may', 'me', \"mean\", \"more\", \"mean\", \"more\", \"most\", \"much\", \"no\", \"not\", \"now\", 'on', \"of\", \"only\", \"or\", \"our\", \"really\", \"say\", \"see\", \"some\", \"something\", \"most\", \"much\", \"no\", \"not\", \"now\", \"of\", \"only\", \"or\", \"our\", \"really\", \"say\", \"see\", \"some\", \"something\", \"take\", \"tell\", \"than\", \"that\", \"the\", \"their\", \"them\", \"then\", \"they\", \"thing\", \"this\", \"to\", \"try\", \"up\", \"us\", \"use\", \"used\", \"uses\", \"very\", \"want\", \"was\", \"way\", \"we\", \"what\", \"when\", \"where\", \"which\", \"who\", \"why\", \"will\", \"with\", \"without\", \"wont\", \"you\", \"your\", \"you're\"]\n",
        "\n",
        "skill_lst = words_skill.split()\n",
        "\n",
        "for s in stopwords:\n",
        "    for w in skill_lst:\n",
        "        if w == s:\n",
        "            skill_lst.remove(w)\n",
        "\n",
        "bag_of_words = {k:skill_lst.count(k) for k in set(skill_lst) if len(k) > 1}\n",
        "bag_of_words = {k:v for k,v in bag_of_words.items() if v > 20}\n",
        "df_words = pd.DataFrame(bag_of_words, index=[0]).T.rename(columns={0:'#'})\n",
        "df_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQa-lKwcECIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_words.sort_values('#', ascending=False).head(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVORMBXvFvr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remote jobs\n",
        "len(re.findall('remote', words_skill))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haKB5z0Z0_vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_bag = sorted(bag_of_words.items(), key=lambda kv: kv[1], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyvOhWf253Df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count cities\n",
        "bag_of_cities = {k:' '.join(city).count(k) for k in set(city)}\n",
        "\n",
        "bag_of_cities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fcrcLZT9f-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bag of jobs\n",
        "\n",
        "job_picks = ['senior', 'python', 'intermediate', 'analyst', 'analysis', 'analytics', 'analista', 'data', 'architect', 'database', 'hackers', 'tech', 'machine', 'learning', 'it', 'ai', 'bi', 'sql', 'software', 'programmer', 'programador', 'scientist', 'sciente', 'engineer', 'engineering', 'developer', 'development', 'artificial', 'intelligence', 'junior']\n",
        "\n",
        "#job = ['data analyst', 'nothing', 'nothing ai']\n",
        "\n",
        "jobs = [word.lower() for j in job for word in j.split()]\n",
        "jobs_selected = [word for word in jobs if word in job_picks]\n",
        "jobs_selected"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7bDcGmImsIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag_of_jobs = {word:jobs_selected.count(word) for word in set(jobs_selected)}\n",
        "  \n",
        "df_jobs = pd.DataFrame(bag_of_jobs, index=[0])\n",
        "df_jobs_sim = df_jobs[['ai', 'python',\t'junior',\t'scientist',\t'machine',\t'learning', 'hackers',\t'software',\t'database',\t'bi', 'it', 'tech',\t'senior',\t'sql',\t'architect',\t'intelligence', 'data']].copy()\n",
        "\n",
        "#df_analyst = [[col] for col in df_jobs if col.startswith('anal')]\n",
        "df_jobs_sim['analyst'] = df_jobs.apply(lambda x: x['analysis'] + x['analista'] + x['analytics'] + x['analyst'], axis=1)\n",
        "df_jobs_sim['engineer'] = df_jobs.apply(lambda x: x['engineer'] + x['engineering'], axis=1)\n",
        "df_jobs_sim['programmer'] = df_jobs.apply(lambda x: x['programmer'] + x['programador'], axis=1)\n",
        "df_jobs_sim['developer'] = df_jobs.apply(lambda x: x['developer'] + x['development'], axis=1)\n",
        "df = df_jobs_sim.T.rename(columns={0:'#'}).sort_values('#', ascending=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8TZu-gjE2vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = np.ogrid[:300, :300]\n",
        "\n",
        "mask = (x - 150) ** 2 + (y - 150) ** 2 > 130 ** 2\n",
        "mask = 255 * mask.astype(int)\n",
        "text_jobs = ' '. join(jobs_selected)\n",
        "wc_jobs = WordCloud(background_color=\"rgba(255, 255, 255, 0)\", mode=\"RGBA\", repeat=True, mask=mask)\n",
        "wc_jobs.generate(text_jobs)\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(wc_jobs, interpolation=\"bilinear\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4PCI0tz-9nD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SALARY COMPARISON\n",
        "#getting all the pages with listings\n",
        "\n",
        "url_dev = 'https://www.payscale.com/research/US/Job=Software_Developer/Salary'\n",
        "url_ana = 'https://www.payscale.com/research/US/Job=Data_Analyst/Salary' \n",
        "url_sci = 'https://www.payscale.com/research/US/Job=Data_Scientist/Salary' \n",
        "url_bus = 'https://www.payscale.com/research/US/Job=Business_Analyst%2C_IT/Salary' \n",
        "\n",
        "urls = [url_dev, url_ana, url_sci, url_bus]\n",
        "salary = []\n",
        "\n",
        "for url in urls:\n",
        "  response_url = requests.get(url)\n",
        "  soup_url = BeautifulSoup(response_url.content, 'lxml')\n",
        "  sal = [element.text[1:3] for element in soup_url.find_all('div', attrs = {'class':'percentile-chart__median'})]\n",
        "  salary += sal\n",
        "\n",
        "to_euros = list(map(lambda x: float(x) * 0.91, salary))\n",
        "\n",
        "job_titles = ['Software Developer', 'Data Analyst', 'Data Scientist', 'Business Analyst']\n",
        "salary_world = list(zip(job_titles, to_euros))\n",
        "in_lisb = [21.975, 15.024, 29.226, 27.289]\n",
        "salary_lisb = list(zip(job_titles, in_lisb))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P75K4rF4oqYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'USA': to_euros, 'Lisbon': in_lisb}, index=job_titles)\n",
        "ax = df.plot.bar(rot=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA1RVZoNouV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}